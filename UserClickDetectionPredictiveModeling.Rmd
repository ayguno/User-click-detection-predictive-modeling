---
title: "Feature Engineering for user click detection predictive modeling"
author: "Ozan Aygun"
date: "12/15/2017"
output: 
   html_document:
        toc: true
        number_sections: true
        depth: 4
        theme: cerulean
        highlight: tango
        df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(results = "markup", fig.align = "center",
                      fig.width = 6, fig.height = 5,message=FALSE,warning=FALSE)
```

# Introduction and summary

# Loading and developing expectations from data

We will start working with the small subset of the training data that contain 100.000 observations just to develops some expectations from the data. The actual training set contains ~ 200 milion observations, we will attempt to download and process it once we locked down our processing and feature engineering pipeline.

```{r, cache=TRUE}
train_sample <- read.csv("train_sample.csv", stringsAsFactors = F)
```

```{r}
str(train_sample)
```
```{r}
apply(train_sample,2,function(x){sum(is.na(x))})
```
```{r}
summary(train_sample)
```

```{r}
apply(train_sample,2, function(x){return(length(unique(x)))})
```

```{r}
table(train_sample$is_attributed)
```

# Data processing and Feature Engineering Pipeline

We will start writing our pipeline function as we continue developing expectations from the sample data set we have.

## Understanding relationship between clicks and IPs

Are the clicks distributed randomly amongst the different IPs? 

YES. Most likely at the end we can remove this feature.

```{r}
library(ggplot2)
ggplot(train_sample,aes(ip,is_attributed,col = factor(is_attributed)))+
        scale_color_manual(values = c("red","navy"))+
        geom_point()
        
```

## Understanding the relationship between clicks and Device type

```{r}
library(ggplot2)
ggplot(train_sample,aes(device,is_attributed,col = factor(is_attributed), alpha(0.2)))+
        scale_color_manual(values = c("red","navy"))+
        geom_point()
        
```

It looks like certain devices are more likely to be used in true events:

```{r}
length(unique(train_sample$device[train_sample$is_attributed == 1]))
```

Therefore, these 25 devices are more likely to be used in true events. We will encode device as a dummy variable:

```{r}
# Creating our processing pipeline
processing_pipeline <- function(dataset){
        require(caret)
        require(dplyr)
        # Convert device to dummy variable
        dataset$device <- as.factor(dataset$device)
        device_dummy <- dummyVars(is_attributed ~ device, dataset)
        dataset <- cbind(dataset,predict(device_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -device)
        
        return(dataset)
}
```

Test the current pipeline on training sample:

```{r, eval= FALSE}
processed_train_sample <- processing_pipeline(train_sample)
```

The pipeline converts device to dummy variable.

## Understanding the relationship between clicks and app type

```{r}
library(ggplot2)
ggplot(train_sample,aes(app,is_attributed,col = factor(is_attributed), alpha(0.2)))+
        scale_color_manual(values = c("red","navy"))+
        geom_point()
        
```

Some apps may be more likely to be downloaded. Convert app into dummy variable by adding this step into our pipeline:

```{r}
# Update our processing pipeline
processing_pipeline <- function(dataset){
        require(caret)
        require(dplyr)
        
        # Convert device to dummy variable
        dataset$device <- as.factor(dataset$device)
        device_dummy <- dummyVars(is_attributed ~ device, dataset)
        dataset <- cbind(dataset,predict(device_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -device)
        
        # Convert app to dummy variable
        dataset$app <- as.factor(dataset$app)
        app_dummy <- dummyVars(is_attributed ~ app, dataset)
        dataset <- cbind(dataset,predict(app_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -app)
        
        
        return(dataset)
}
```

Test the current pipeline on training sample:

```{r, eval= FALSE}
# It works!
processed_train_sample <- processing_pipeline(train_sample)
```

## Understanding the relationship between clicks and os type

```{r}
library(ggplot2)
ggplot(train_sample,aes(os,is_attributed,col = factor(is_attributed), alpha(0.2)))+
        scale_color_manual(values = c("red","navy"))+
        geom_point()
        
```

We will add os dummy variable by updating our pipeline:

```{r}
# Update our processing pipeline
processing_pipeline <- function(dataset){
        require(caret)
        require(dplyr)
        
        # Convert device to dummy variable
        dataset$device <- as.factor(dataset$device)
        device_dummy <- dummyVars(is_attributed ~ device, dataset)
        dataset <- cbind(dataset,predict(device_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -device)
        
        # Convert app to dummy variable
        dataset$app <- as.factor(dataset$app)
        app_dummy <- dummyVars(is_attributed ~ app, dataset)
        dataset <- cbind(dataset,predict(app_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -app)
        
        # Convert os to dummy variable
        dataset$os <- as.factor(dataset$os)
        os_dummy <- dummyVars(is_attributed ~ os, dataset)
        dataset <- cbind(dataset,predict(os_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -os)
        
        return(dataset)
}
```

Test the current pipeline on training sample:

```{r, eval= FALSE}
# It works!
processed_train_sample <- processing_pipeline(train_sample)
```

## Understanding the relationship between clicks and channel type

```{r}
library(ggplot2)
ggplot(train_sample,aes(channel,is_attributed,col = factor(is_attributed), alpha(0.2)))+
        scale_color_manual(values = c("red","navy"))+
        geom_point()
        
```

This rather looks random, but not as much as the IPs. My intuition says that this could be a partiallly relevant feature, so will convert it to dummy variable:

```{r}
# Update our processing pipeline
processing_pipeline <- function(dataset){
        require(caret)
        require(dplyr)
        
        # Convert device to dummy variable
        dataset$device <- as.factor(dataset$device)
        device_dummy <- dummyVars(is_attributed ~ device, dataset)
        dataset <- cbind(dataset,predict(device_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -device)
        
        # Convert app to dummy variable
        dataset$app <- as.factor(dataset$app)
        app_dummy <- dummyVars(is_attributed ~ app, dataset)
        dataset <- cbind(dataset,predict(app_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -app)
        
        # Convert os to dummy variable
        dataset$os <- as.factor(dataset$os)
        os_dummy <- dummyVars(is_attributed ~ os, dataset)
        dataset <- cbind(dataset,predict(os_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -os)
        
        # Convert channel to dummy variable
        dataset$channel <- as.factor(dataset$channel)
        channel_dummy <- dummyVars(is_attributed ~ channel, dataset)
        dataset <- cbind(dataset,predict(channel_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -channel)
        
        return(dataset)
}
```

Test the current pipeline on training sample:

```{r, eval= FALSE}
# It works!
processed_train_sample <- processing_pipeline(train_sample)
```

## Exploring the relationship between click time and true events

We have 2 kinds of time stamps as features:

- click_time: timestamp of click (UTC)
- attributed_time: if user download the app for after clicking an ad, this is the time of the app download

### Exploring the position of attributed_time within click_times

```{r}
# Convert the time stamps to true time variables
require(lubridate)

#Fill the empty spaces with NA
train_sample$click_time[train_sample$click_time == ""] <- NA
train_sample$attributed_time[train_sample$attributed_time == ""] <- NA

# Convert to true time variables
train_sample$click_time <- ymd_hms(train_sample$click_time)
train_sample$attributed_time <- ymd_hms(train_sample$attributed_time)
```


```{r}
library(ggplot2)
attributed_ip <- train_sample$ip[which(train_sample$is_attributed == 1)]
attributed_train <- train_sample[which(train_sample$ip %in% attributed_ip),]

# Randomly choose 10 ips to inspect
random_ips <- sample(unique(attributed_train$ip),10)
random_attributed_train <- attributed_train[which(attributed_train$ip %in% random_ips),]

ggplot(random_attributed_train, aes(x = click_time))+
        facet_grid(factor(random_attributed_train$ip) ~ .)+
        geom_point(aes(x = click_time ,y = 1)) +
        geom_vline(xintercept = random_attributed_train$attributed_time)
```

We see that downloading can take place at any point of the clicking periof from a particular attributed ip.

### Exploring the impact of total click time from an ip and true events

```{r}
library(dplyr)
total_click_time <- train_sample %>% group_by(ip) %>% summarise(total_click_time = max(click_time) - min(click_time))
explore <- merge(train_sample,total_click_time, by = "ip")
ggplot(explore, aes(x = factor(is_attributed),y = total_click_time))+
        geom_boxplot()
```

```{r}
ggplot(explore, aes(x = total_click_time))+
        facet_grid( factor(explore$is_attributed) ~ .)+
        geom_histogram(fill = "navy", bins = 100)
```

This feature has some potential. We note that the true events are generally associated with shorter click times (wihin a few seconds), but there are also outliers. Let's update out processing pipeline to include this new feature:

```{r}
# Update our processing pipeline
processing_pipeline <- function(dataset){
        require(caret)
        require(dplyr)
        require(lubridate)
        
        # Convert device to dummy variable
        dataset$device <- as.factor(dataset$device)
        device_dummy <- dummyVars(is_attributed ~ device, dataset)
        dataset <- cbind(dataset,predict(device_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -device)
        
        # Convert app to dummy variable
        dataset$app <- as.factor(dataset$app)
        app_dummy <- dummyVars(is_attributed ~ app, dataset)
        dataset <- cbind(dataset,predict(app_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -app)
        
        # Convert os to dummy variable
        dataset$os <- as.factor(dataset$os)
        os_dummy <- dummyVars(is_attributed ~ os, dataset)
        dataset <- cbind(dataset,predict(os_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -os)
        
        # Convert channel to dummy variable
        dataset$channel <- as.factor(dataset$channel)
        channel_dummy <- dummyVars(is_attributed ~ channel, dataset)
        dataset <- cbind(dataset,predict(channel_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -channel)
        
        ###############################
        # Add total_click_time feature
        ###############################
        # Fill the empty spaces with NA
        dataset$click_time[dataset$click_time == ""] <- NA
        dataset$attributed_time[dataset$attributed_time == ""] <- NA
        
        # Convert to true time variables
        dataset$click_time <- ymd_hms(dataset$click_time)
        dataset$attributed_time <- ymd_hms(dataset$attributed_time)
        
        total_click_frame <- dataset %>% group_by(ip) %>% summarise(total_click_time = max(click_time) - min(click_time))
        dataset <- merge(dataset,total_click_frame, by = "ip", sort = FALSE)
        
        return(dataset)
}
```

```{r, cache=TRUE}
train_sample <- read.csv("train_sample.csv", stringsAsFactors = F)
```

Test the current pipeline on training sample:

```{r, eval= FALSE}
# It works!
processed_train_sample <- processing_pipeline(train_sample)
```

### Exploring the impact of total number of clicks from an ip and true events

```{r}
require(dplyr)
require(ggplot2)
total_clicks_frame <- train_sample %>% group_by(ip) %>% summarise(total_clicks = n())
explore <- merge(train_sample,total_clicks_frame, by = "ip", sort =  FALSE)
ggplot(explore, aes(x=factor(is_attributed), y=log(total_clicks)))+
        geom_boxplot()
```

This is a good feature. We will add log(total_clicks + 1) as a new feature by updating our pipeline:

```{r}
# Update our processing pipeline
processing_pipeline <- function(dataset){
        require(caret)
        require(dplyr)
        require(lubridate)
        
        # Convert device to dummy variable
        dataset$device <- as.factor(dataset$device)
        device_dummy <- dummyVars(is_attributed ~ device, dataset)
        dataset <- cbind(dataset,predict(device_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -device)
        
        # Convert app to dummy variable
        dataset$app <- as.factor(dataset$app)
        app_dummy <- dummyVars(is_attributed ~ app, dataset)
        dataset <- cbind(dataset,predict(app_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -app)
        
        # Convert os to dummy variable
        dataset$os <- as.factor(dataset$os)
        os_dummy <- dummyVars(is_attributed ~ os, dataset)
        dataset <- cbind(dataset,predict(os_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -os)
        
        # Convert channel to dummy variable
        dataset$channel <- as.factor(dataset$channel)
        channel_dummy <- dummyVars(is_attributed ~ channel, dataset)
        dataset <- cbind(dataset,predict(channel_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -channel)
        
        ###############################
        # Add total_click_time feature
        ###############################
        # Fill the empty spaces with NA
        dataset$click_time[dataset$click_time == ""] <- NA
        dataset$attributed_time[dataset$attributed_time == ""] <- NA
        
        # Convert to true time variables
        dataset$click_time <- ymd_hms(dataset$click_time)
        dataset$attributed_time <- ymd_hms(dataset$attributed_time)
        
        total_click_frame <- dataset %>% group_by(ip) %>% summarise(total_click_time = max(click_time) - min(click_time))
        dataset <- merge(dataset,total_click_frame, by = "ip", sort = FALSE)
        
        ################################
        # Add total_clicks feature
        ###############################
        total_clicks_frame <- dataset %>% group_by(ip) %>% summarise(total_clicks = n())
        total_clicks_frame$total_clicks <- log(total_clicks_frame$total_clicks + 1)
        colnames(total_clicks_frame)[2] <- "log_total_clicks"
        dataset <- merge(dataset,total_clicks_frame, by = "ip", sort =  FALSE)
        
        return(dataset)
}
```

Test the current pipeline on training sample:

```{r, eval= FALSE}
# It works!
processed_train_sample <- processing_pipeline(train_sample)
```

### Explore the relationship between total_time & total_clicks interaction and true events

```{r}
plot(processed_train_sample$log_total_clicks,log(as.numeric(processed_train_sample$total_click_time+1)), col = ifelse(processed_train_sample$is_attributed == 1, "red","blue"), pch = 19, 
     cex = ifelse(processed_train_sample$is_attributed == 1,1,0.1), alpha = 0.8)
```

We note that there is some relationship between these two features to explain true events. 

```{r}
# Their ratio is not any better than one feature
library(ggplot2)
ggplot(processed_train_sample,aes(factor(is_attributed),log(as.numeric(total_click_time+1))/log_total_clicks))+
geom_boxplot()
```

```{r}
# Their product is not any better than one feature
library(ggplot2)
ggplot(processed_train_sample,aes(factor(is_attributed),log(as.numeric(total_click_time+1)) * log_total_clicks))+
geom_boxplot()
```

# Finalizing the processing and feature engineering pipeline

Before we finalize the pipeline, we will add the following steps:

- convert total_click_time to log scale
- remove ip, click_time, attributed_time features
- make feature names Python compatible

```{r}
# Update our processing pipeline
processing_pipeline <- function(dataset){
        require(caret)
        require(dplyr)
        require(lubridate)
        
        # Convert device to dummy variable
        dataset$device <- as.factor(dataset$device)
        device_dummy <- dummyVars(is_attributed ~ device, dataset)
        dataset <- cbind(dataset,predict(device_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -device)
        
        # Convert app to dummy variable
        dataset$app <- as.factor(dataset$app)
        app_dummy <- dummyVars(is_attributed ~ app, dataset)
        dataset <- cbind(dataset,predict(app_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -app)
        
        # Convert os to dummy variable
        dataset$os <- as.factor(dataset$os)
        os_dummy <- dummyVars(is_attributed ~ os, dataset)
        dataset <- cbind(dataset,predict(os_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -os)
        
        # Convert channel to dummy variable
        dataset$channel <- as.factor(dataset$channel)
        channel_dummy <- dummyVars(is_attributed ~ channel, dataset)
        dataset <- cbind(dataset,predict(channel_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -channel)
        
        ###############################
        # Add total_click_time feature
        ###############################
        # Fill the empty spaces with NA
        dataset$click_time[dataset$click_time == ""] <- NA
        dataset$attributed_time[dataset$attributed_time == ""] <- NA
        
        # Convert to true time variables
        dataset$click_time <- ymd_hms(dataset$click_time)
        dataset$attributed_time <- ymd_hms(dataset$attributed_time)
        
        total_click_frame <- dataset %>% group_by(ip) %>% summarise(total_click_time = max(click_time) - min(click_time))
        total_click_frame$total_click_time <- log(as.numeric(total_click_frame$total_click_time + 1))
        colnames(total_click_frame)[2] <- "log_total_click_time"
        dataset <- merge(dataset,total_click_frame, by = "ip", sort = FALSE)
        
        ################################
        # Add total_clicks feature
        ###############################
        total_clicks_frame <- dataset %>% group_by(ip) %>% summarise(total_clicks = n())
        total_clicks_frame$total_clicks <- log(total_clicks_frame$total_clicks + 1)
        colnames(total_clicks_frame)[2] <- "log_total_clicks"
        dataset <- merge(dataset,total_clicks_frame, by = "ip", sort =  FALSE)
        
        ################################
        # Remove base features
        ###############################
        
        dataset <- dplyr::select(dataset, -ip)
        dataset <- dplyr::select(dataset, -click_time)
        dataset <- dplyr::select(dataset, -attributed_time)
        
        #######################################
        # Make feature names Python compatible 
        #######################################
        
        colnames(dataset) <- sapply(colnames(dataset), function(x){return(gsub("\\.","_",x))})
        
        return(dataset)
}
```

Test the current pipeline on training sample:

```{r, eval= FALSE}
# It works!
processed_train_sample <- processing_pipeline(train_sample)
```

# Processing the test data set

The next step is to process the test set we downloaded using the same pipeline:

```{r,eval=FALSE}
start = Sys.Date()
test_set <- read.csv("test.csv", stringsAsFactors = FALSE)
Sys.Date() - start
```

```{r}
head(test_set)
```

```{r}
tail(test_set)
```

Save and remove the click_id for future use during submissions:

```{r}
click_id = data.frame(click_id = test_set$click_id)
write.csv(click_id,"click_id.csv", row.names = FALSE)
```

```{r}
test_set <- dplyr::select(test_set, - click_id)
```


We need to update the pipeline to remove attributed_time only from the training sets.

In addition we also need to lock down the dummy transformation objects developed using the training sample. These will be reused by all other sets we will process to ensure consistency:


```{r}
# Lock down the dummy processors
require(caret)
# Convert device to dummy variable
        train_sample$device <- as.factor(train_sample$device)
        device_dummy <- dummyVars(is_attributed ~ device, train_sample)
        saveRDS(object = device_dummy,"device_dummy.rds")   
        
 # Convert app to dummy variable
        train_sample$app <- as.factor(train_sample$app)
        app_dummy <- dummyVars(is_attributed ~ app, train_sample)
        saveRDS(object = app_dummy,"app_dummy.rds")
        
# Convert os to dummy variable
        train_sample$os <- as.factor(train_sample$os)
        os_dummy <- dummyVars(is_attributed ~ os, train_sample)
        saveRDS(object = os_dummy,"os_dummy.rds")
        
# Convert channel to dummy variable
        train_sample$channel <- as.factor(train_sample$channel)
        channel_dummy <- dummyVars(is_attributed ~ channel, train_sample)
        saveRDS(object = channel_dummy,"channel_dummy.rds")
```

```{r}
                
# Update our processing pipeline
processing_pipeline <- function(dataset){
        require(caret)
        require(dplyr)
        require(lubridate)
        
        # Convert device to dummy variable
        dataset$device <- as.factor(dataset$device)
        device_dummy <- readRDS("device_dummy.rds")
        dataset <- cbind(dataset,predict(device_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -device)
        
        # Convert app to dummy variable
        dataset$app <- as.factor(dataset$app)
        app_dummy <- readRDS("app_dummy.rds")
        dataset <- cbind(dataset,predict(app_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -app)
        
        # Convert os to dummy variable
        dataset$os <- as.factor(dataset$os)
        os_dummy <- readRDS("os_dummy.rds")
        dataset <- cbind(dataset,predict(os_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -os)
        
        # Convert channel to dummy variable
        dataset$channel <- as.factor(dataset$channel)
        channel_dummy <- readRDS("channel_dummy.rds")
        dataset <- cbind(dataset,predict(channel_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -channel)
        
        ###############################
        # Add total_click_time feature
        ###############################
        # Fill the empty spaces with NA
        dataset$click_time[dataset$click_time == ""] <- NA
        # Convert to true time variables
        dataset$click_time <- ymd_hms(dataset$click_time)
        total_click_frame <- dataset %>% group_by(ip) %>% summarise(total_click_time = max(click_time) - min(click_time))
        total_click_frame$total_click_time <- log(as.numeric(total_click_frame$total_click_time + 1))
        colnames(total_click_frame)[2] <- "log_total_click_time"
        dataset <- merge(dataset,total_click_frame, by = "ip", sort = FALSE)
        
        ################################
        # Add total_clicks feature
        ###############################
        total_clicks_frame <- dataset %>% group_by(ip) %>% summarise(total_clicks = n())
        total_clicks_frame$total_clicks <- log(total_clicks_frame$total_clicks + 1)
        colnames(total_clicks_frame)[2] <- "log_total_clicks"
        dataset <- merge(dataset,total_clicks_frame, by = "ip", sort =  FALSE)
        
        ################################
        # Remove base features
        ###############################
        
        dataset <- dplyr::select(dataset, -ip)
        dataset <- dplyr::select(dataset, -click_time)
        
        if("attributed_time" %in% colnames(dataset) ){dataset <- dplyr::select(dataset, -attributed_time)}
        
        #######################################
        # Make feature names Python compatible 
        #######################################
        
        colnames(dataset) <- sapply(colnames(dataset), function(x){return(gsub("\\.","_",x))})
        
        return(dataset)
}
```

Test the current pipeline on training sample:

```{r, eval= FALSE}
# It works!
processed_train_sample <- processing_pipeline(train_sample)
```


#  Processing and saving the test set

Let's process and save the test set in chunks of 10000 samples:

```{r, eval= FALSE}

chunks = seq(from = 1, to= nrow(test_set), by = 10000)
chunks <- c(chunks,nrow(test_set))
```

```{r}
#for(i in 1:(length(chunks)-1)){
for(i in 1:5){
        
        dataset <- test_set[chunks[i]:chunks[i+1],]
        processed_dataset <- processing_pipeline(dataset)
        write.csv(dataset,"test_processed.csv", row.names = FALSE, append = TRUE)
        print(paste0("Processed chunk:", chunks[i],"\n"))
        
}

```

# Updating the caret-based pipeline to allow feature extraction at the first instance

We note that some features have levels that might only exist in the entire training set. dummyVars can not deal with this type of problem. Therefore, we will further customize the processing pipeline to tackle this problem:

```{r}
                
# Update our processing pipeline
processing_pipeline <- function(dataset){
        require(caret)
        require(dplyr)
        require(lubridate)
        
        # Convert device to factor variable
        dataset$device <- as.factor(dataset$device)
        # Convert app to factor variable
        dataset$app <- as.factor(dataset$app)
        # Convert os to factor variable
        dataset$os <- as.factor(dataset$os)
        # Convert channel to factor variable
        dataset$channel <- as.factor(dataset$channel)
        
        # A generic function that gets a data set and converts all factor variables to dummy variables
        convert.to.dummy <- function(data.set){
                cat.var <-NULL
                temp.data <- data.frame(1:nrow(data.set))
                   for(i in 1:ncol(data.set)){
                        if(class(data.set[,i]) == "factor"){
                                cat.var <- c(cat.var,i)
                                factor.levels <- levels(data.set[,i]) 
                                # Try to find a way to classify NA's as "NO" 
                                # otherwise they generate problem downstream
                                        # First check if there is any 'NA-level'
                                        if(any(is.na(data.set[,i]))){
                                                dummy.vector = ifelse(is.na(data.set[,i]),1,0)
                                                dummy.vector <- data.frame(dummy.vector)
                                                colnames(dummy.vector)[1] = paste("NO",names((data.set)[i]),
                                                                                  sep = ".")
                                                temp.data <- cbind(temp.data,dummy.vector)
                                        }
                                
                                        for(j in seq_along(factor.levels)){ # Then deal with normal factor levels
                                        dummy.vector = ifelse(data.set[,i] == factor.levels[j],1,0)
                                        
                                        #Since we already dealt with NAs above
                                        if(any(is.na(dummy.vector))){dummy.vector[is.na(dummy.vector)] <- 0} 
                                        
                                        dummy.vector <- data.frame(dummy.vector)
                                        colnames(dummy.vector)[1] = paste(names((data.set)[i]),
                                                                          factor.levels[j],sep = ".")
                                        temp.data <- cbind(temp.data,dummy.vector)
                                        }
                        }
                   }
                   #Remove the original categorical variables from data.set
                   data.set <- data.set[,-cat.var]     
                   #Add the dummy.variable set
                   temp.data <- temp.data[,-1] # remove the unnecessary column
                   data.set <- cbind(data.set,temp.data)
                   
                   return(data.set)     
        }
        
        # Use convert.to.dummy to generate dummy variables
        dataset <- convert.to.dummy(dataset)
        
        ###############################
        # Add total_click_time feature
        ###############################
        # Fill the empty spaces with NA
        dataset$click_time[dataset$click_time == ""] <- NA
        # Convert to true time variables
        dataset$click_time <- ymd_hms(dataset$click_time)
        total_click_frame <- dataset %>% group_by(ip) %>% summarise(total_click_time = max(click_time) - min(click_time))
        total_click_frame$total_click_time <- log(as.numeric(total_click_frame$total_click_time + 1))
        colnames(total_click_frame)[2] <- "log_total_click_time"
        dataset <- merge(dataset,total_click_frame, by = "ip", sort = FALSE)
        
        ################################
        # Add total_clicks feature
        ###############################
        total_clicks_frame <- dataset %>% group_by(ip) %>% summarise(total_clicks = n())
        total_clicks_frame$total_clicks <- log(total_clicks_frame$total_clicks + 1)
        colnames(total_clicks_frame)[2] <- "log_total_clicks"
        dataset <- merge(dataset,total_clicks_frame, by = "ip", sort =  FALSE)
        
        ################################
        # Remove base features
        ###############################
        
        dataset <- dplyr::select(dataset, -ip)
        dataset <- dplyr::select(dataset, -click_time)
        
        if("attributed_time" %in% colnames(dataset) ){dataset <- dplyr::select(dataset, -attributed_time)}
        
        #######################################
        # Make feature names Python compatible 
        #######################################
        
        colnames(dataset) <- sapply(colnames(dataset), function(x){return(gsub("\\.","_",x))})
        
        return(dataset)
}
```

```{r}
processed_train_sample2 <- processing_pipeline(train_sample)
```

```{r}
head(processed_train_sample$app_14)
head(processed_train_sample2$app_14)
```
```{r}
tail(processed_train_sample$os_36,200)
tail(processed_train_sample2$os_36,200)
```

It looks like our modified pipeline generates an equivalent set of dummy variables.

##  Processing and saving the test set

Let's process and save the test set  using the updated pipeline:


```{r}
setwd("/Volumes/500GB/Data_science/Kaggle/User-click-detection-predictive-modeling")
start = Sys.time()
test_set <- read.csv("test.csv", stringsAsFactors = FALSE)
Sys.time() - start
```

```{r}
print(paste0("Starting time: ", Sys.time()))
# Can we process the test data in chunks?
chunks = 0
processed_dataset = processing_pipeline(test_set[1:100,])
start = 101
for(i in 1:187904){
        chunks = chunks + 1
        endrow = start + 99
        if(endrow > nrow(test_set)){endrow <- nrow(test_set)}
        print(paste0("Start chunk:", chunks))
        dataset <- test_set[start:endrow,]
        processed_dataset_temp <- processing_pipeline(dataset)
        processed_dataset <- merge(processed_dataset,processed_dataset_temp, all = TRUE)
        print(paste0("Processed chunk:", chunks))
        start = start + 100
}
print(paste0("End processing starting writing: ", Sys.time()))
write.csv(processed_dataset,file = "test_processed.csv", row.names = FALSE)
print(paste0("Finished writing: ", Sys.time()))
```

This type of pipelining is not computationally efficient. I will try to address the problem using a Python pipeline and feature selection instead.