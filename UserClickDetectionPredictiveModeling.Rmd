---
title: "Feature Engineering for user click detection predictive modeling"
author: "Ozan Aygun"
date: "12/15/2017"
output: 
   html_document:
        toc: true
        number_sections: true
        depth: 4
        theme: cerulean
        highlight: tango
        df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(results = "markup", fig.align = "center",
                      fig.width = 6, fig.height = 5,message=FALSE,warning=FALSE)
```

# Introduction and summary

# Loading and developing expectations from data

We will start working with the small subset of the training data that contain 100.000 observations just to develops some expectations from the data. The actual training set contains ~ 200 milion observations, we will attempt to download and process it once we locked down our processing and feature engineering pipeline.

```{r, cache=TRUE}
train_sample <- read.csv("train_sample.csv", stringsAsFactors = F)
```

```{r}
str(train_sample)
```
```{r}
apply(train_sample,2,function(x){sum(is.na(x))})
```
```{r}
summary(train_sample)
```

```{r}
apply(train_sample,2, function(x){return(length(unique(x)))})
```

```{r}
table(train_sample$is_attributed)
```

# Data processing and Feature Engineering Pipeline

We will start writing our pipeline function as we continue developing expectations from the sample data set we have.

## Understanding relationship between clicks and IPs

Are the clicks distributed randomly amongst the different IPs? 

YES. Most likely at the end we can remove this feature.

```{r}
library(ggplot2)
ggplot(train_sample,aes(ip,is_attributed,col = factor(is_attributed)))+
        scale_color_manual(values = c("red","navy"))+
        geom_point()
        
```

## Understanding the relationship between clicks and Device type:

```{r}
library(ggplot2)
ggplot(train_sample,aes(device,is_attributed,col = factor(is_attributed), alpha(0.2)))+
        scale_color_manual(values = c("red","navy"))+
        geom_point()
        
```

It looks like certain devices are more likely to be used in true events:

```{r}
length(unique(train_sample$device[train_sample$is_attributed == 1]))
```

Therefore, these 25 devices are more likely to be used in true events. We will encode device as a dummy variable:

```{r}
# Creating our processing pipeline
processing_pipeline <- function(dataset){
        require(caret)
        require(dplyr)
        # Convert device to dummy variable
        dataset$device <- as.factor(dataset$device)
        device_dummy <- dummyVars(is_attributed ~ device, dataset)
        dataset <- cbind(dataset,predict(device_dummy, newdata = dataset))
        dataset <- dplyr::select(dataset, -device)
        
        return(dataset)
}
```

Test the current pipeline on training sample:

```{r, eval= FALSE}
processed_train_sample <- processing_pipeline(train_sample)
```

The pipeline converts device to dummy variable.

## 
